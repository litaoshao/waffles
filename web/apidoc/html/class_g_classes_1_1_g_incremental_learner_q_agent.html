<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>GClasses: GClasses::GIncrementalLearnerQAgent Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript">
$(document).ready(initResizable);
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.7.3 -->
<div id="top">
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">GClasses</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
</div>
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
  initNavTree('class_g_classes_1_1_g_incremental_learner_q_agent.html','');
</script>
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a>  </div>
  <div class="headertitle">
<h1>GClasses::GIncrementalLearnerQAgent Class Reference</h1>  </div>
</div>
<div class="contents">
<!-- doxytag: class="GClasses::GIncrementalLearnerQAgent" --><!-- doxytag: inherits="GClasses::GQLearner" -->
<p>This is an implementation of <a class="el" href="class_g_classes_1_1_g_q_learner.html" title="The base class of a Q-Learner. To use this class, there are four abstract methods you&#39;ll need to ...">GQLearner</a> that uses an incremental learner for its Q-table and a SoftMax (usually pick the best action, but sometimes randomly pick the action) strategy to balance between exploration vs exploitation. To use this class, you need to supply an incremental learner (see the comment for the constructor for more details) and to implement the GetRewardForLastAction method.  
<a href="#_details">More...</a></p>

<p><code>#include &lt;GReinforcement.h&gt;</code></p>
<div class="dynheader">
Inheritance diagram for GClasses::GIncrementalLearnerQAgent:</div>
<div class="dyncontent">
 <div class="center">
  <img src="class_g_classes_1_1_g_incremental_learner_q_agent.png" usemap="#GClasses::GIncrementalLearnerQAgent_map" alt=""/>
  <map id="GClasses::GIncrementalLearnerQAgent_map" name="GClasses::GIncrementalLearnerQAgent_map">
<area href="class_g_classes_1_1_g_q_learner.html" alt="GClasses::GQLearner" shape="rect" coords="0,56,233,80"/>
<area href="class_g_classes_1_1_g_policy_learner.html" alt="GClasses::GPolicyLearner" shape="rect" coords="0,0,233,24"/>
</map>
 </div></div>

<p><a href="class_g_classes_1_1_g_incremental_learner_q_agent-members.html">List of all members.</a></p>
<table class="memberdecls">
<tr><td colspan="2"><h2><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#a27cec314cf5aef316b0eb6c5f1a2feac">GIncrementalLearnerQAgent</a> (<a class="el" href="class_g_classes_1_1smart__ptr.html">sp_relation</a> &amp;pObsControlRelation, <a class="el" href="class_g_classes_1_1_g_incremental_learner.html">GIncrementalLearner</a> *pQTable, int actionDims, double *pInitialState, <a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *pRand, <a class="el" href="class_g_classes_1_1_g_agent_action_iterator.html">GAgentActionIterator</a> *pActionIterator, double softMaxThresh)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">pQTable must be an incremental learner. If the relation for pQTable has n attributes, then the first (n-1) attributes refer to the sense (state) and action, and the last attribute refers to the Q-value (the current estimate of the utility of performing that action in that state). For actionDims, see the comment for <a class="el" href="class_g_classes_1_1_g_policy_learner.html#aae6d5bdc9c85eda3c2d03ce3f57cdd60" title="actionDims specifies how many dimensions are in the action vector. (For example, if your agent has a ...">GPolicyLearner::GPolicyLearner</a>. pInitialState is the initial sense vector. If softMaxThresh is 0, it always picks a random action. If softMaxThresh is 1, it always picks the best action. For values in between, it does something in between.  <a href="#a27cec314cf5aef316b0eb6c5f1a2feac"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#a6ec404c29da1ce89b0b71e5eaef58386">~GIncrementalLearnerQAgent</a> ()</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#a408da3ccfb79be4da4ce5b94e135417a">getQValue</a> (const double *pState, const double *pAction)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">See the comment for GQLearner::GetQValue.  <a href="#a408da3ccfb79be4da4ce5b94e135417a"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#ae02583c57303a86e45af9f631bbed665">setQValue</a> (const double *pState, const double *pAction, double qValue)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">See the comment for GQLearner::SetQValue.  <a href="#ae02583c57303a86e45af9f631bbed665"></a><br/></td></tr>
<tr><td colspan="2"><h2><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#a21ae8e8bae94fbc24d797f61f5cbc6c5">chooseAction</a> (const double *pSenses, double *pOutActions)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">This method picks the action during training. This method is called by refinePolicyAndChooseNextAction. (If it makes things easier, the agent may actually perform the action here, but it's a better practise to wait until refinePolicyAndChooseNextAction returns, because that keeps the "thinking" and "acting" stages separated from each other.) One way to pick the next action is to call GetQValue for all possible actions in the current state, and pick the one with the highest Q-value. But if you always pick the best action, you'll never discover things you don't already know about, so you need to find some balance between exploration and exploitation. One way to do this is to usually pick the best action, but sometimes pick a random action.  <a href="#a21ae8e8bae94fbc24d797f61f5cbc6c5"></a><br/></td></tr>
<tr><td colspan="2"><h2><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_incremental_learner.html">GIncrementalLearner</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#ad3970dbfa1f2c2bae7445bad7258d722">m_pQTable</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">double *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#af53f57da129856b8686a68671f02dcdd">m_pBuf</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#a5212a0fb6c453cf0e743355b2714898f">m_softMaxThresh</a></td></tr>
</table>
<hr/><a name="_details"></a><h2>Detailed Description</h2>
<div class="textblock"><p>This is an implementation of <a class="el" href="class_g_classes_1_1_g_q_learner.html" title="The base class of a Q-Learner. To use this class, there are four abstract methods you&#39;ll need to ...">GQLearner</a> that uses an incremental learner for its Q-table and a SoftMax (usually pick the best action, but sometimes randomly pick the action) strategy to balance between exploration vs exploitation. To use this class, you need to supply an incremental learner (see the comment for the constructor for more details) and to implement the GetRewardForLastAction method. </p>
</div><hr/><h2>Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="a27cec314cf5aef316b0eb6c5f1a2feac"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::GIncrementalLearnerQAgent" ref="a27cec314cf5aef316b0eb6c5f1a2feac" args="(sp_relation &amp;pObsControlRelation, GIncrementalLearner *pQTable, int actionDims, double *pInitialState, GRand *pRand, GAgentActionIterator *pActionIterator, double softMaxThresh)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">GClasses::GIncrementalLearnerQAgent::GIncrementalLearnerQAgent </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1smart__ptr.html">sp_relation</a> &amp;&#160;</td>
          <td class="paramname"><em>pObsControlRelation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_incremental_learner.html">GIncrementalLearner</a> *&#160;</td>
          <td class="paramname"><em>pQTable</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>actionDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>pInitialState</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *&#160;</td>
          <td class="paramname"><em>pRand</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_agent_action_iterator.html">GAgentActionIterator</a> *&#160;</td>
          <td class="paramname"><em>pActionIterator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>softMaxThresh</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>pQTable must be an incremental learner. If the relation for pQTable has n attributes, then the first (n-1) attributes refer to the sense (state) and action, and the last attribute refers to the Q-value (the current estimate of the utility of performing that action in that state). For actionDims, see the comment for <a class="el" href="class_g_classes_1_1_g_policy_learner.html#aae6d5bdc9c85eda3c2d03ce3f57cdd60" title="actionDims specifies how many dimensions are in the action vector. (For example, if your agent has a ...">GPolicyLearner::GPolicyLearner</a>. pInitialState is the initial sense vector. If softMaxThresh is 0, it always picks a random action. If softMaxThresh is 1, it always picks the best action. For values in between, it does something in between. </p>

</div>
</div>
<a class="anchor" id="a6ec404c29da1ce89b0b71e5eaef58386"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::~GIncrementalLearnerQAgent" ref="a6ec404c29da1ce89b0b71e5eaef58386" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual GClasses::GIncrementalLearnerQAgent::~GIncrementalLearnerQAgent </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

</div>
</div>
<hr/><h2>Member Function Documentation</h2>
<a class="anchor" id="a21ae8e8bae94fbc24d797f61f5cbc6c5"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::chooseAction" ref="a21ae8e8bae94fbc24d797f61f5cbc6c5" args="(const double *pSenses, double *pOutActions)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GIncrementalLearnerQAgent::chooseAction </td>
          <td>(</td>
          <td class="paramtype">const double *&#160;</td>
          <td class="paramname"><em>pSenses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>pOutActions</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td><code> [protected, virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>This method picks the action during training. This method is called by refinePolicyAndChooseNextAction. (If it makes things easier, the agent may actually perform the action here, but it's a better practise to wait until refinePolicyAndChooseNextAction returns, because that keeps the "thinking" and "acting" stages separated from each other.) One way to pick the next action is to call GetQValue for all possible actions in the current state, and pick the one with the highest Q-value. But if you always pick the best action, you'll never discover things you don't already know about, so you need to find some balance between exploration and exploitation. One way to do this is to usually pick the best action, but sometimes pick a random action. </p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_q_learner.html#a40f05909e96c2dd4990a6a242dcc6453">GClasses::GQLearner</a>.</p>

</div>
</div>
<a class="anchor" id="a408da3ccfb79be4da4ce5b94e135417a"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::getQValue" ref="a408da3ccfb79be4da4ce5b94e135417a" args="(const double *pState, const double *pAction)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual double GClasses::GIncrementalLearnerQAgent::getQValue </td>
          <td>(</td>
          <td class="paramtype">const double *&#160;</td>
          <td class="paramname"><em>pState</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double *&#160;</td>
          <td class="paramname"><em>pAction</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>See the comment for GQLearner::GetQValue. </p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_q_learner.html#a85b97fc5300546db37e92098ddd069f9">GClasses::GQLearner</a>.</p>

</div>
</div>
<a class="anchor" id="ae02583c57303a86e45af9f631bbed665"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::setQValue" ref="ae02583c57303a86e45af9f631bbed665" args="(const double *pState, const double *pAction, double qValue)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GIncrementalLearnerQAgent::setQValue </td>
          <td>(</td>
          <td class="paramtype">const double *&#160;</td>
          <td class="paramname"><em>pState</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double *&#160;</td>
          <td class="paramname"><em>pAction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>qValue</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>See the comment for GQLearner::SetQValue. </p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_q_learner.html#a3d03ef30220ecb29362a77515a51fb7e">GClasses::GQLearner</a>.</p>

</div>
</div>
<hr/><h2>Member Data Documentation</h2>
<a class="anchor" id="af53f57da129856b8686a68671f02dcdd"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::m_pBuf" ref="af53f57da129856b8686a68671f02dcdd" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double* <a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#af53f57da129856b8686a68671f02dcdd">GClasses::GIncrementalLearnerQAgent::m_pBuf</a><code> [protected]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

</div>
</div>
<a class="anchor" id="ad3970dbfa1f2c2bae7445bad7258d722"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::m_pQTable" ref="ad3970dbfa1f2c2bae7445bad7258d722" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_incremental_learner.html">GIncrementalLearner</a>* <a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#ad3970dbfa1f2c2bae7445bad7258d722">GClasses::GIncrementalLearnerQAgent::m_pQTable</a><code> [protected]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

</div>
</div>
<a class="anchor" id="a5212a0fb6c453cf0e743355b2714898f"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::m_softMaxThresh" ref="a5212a0fb6c453cf0e743355b2714898f" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double <a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#a5212a0fb6c453cf0e743355b2714898f">GClasses::GIncrementalLearnerQAgent::m_softMaxThresh</a><code> [protected]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

</div>
</div>
</div>
</div>
  <div id="nav-path" class="navpath">
    <ul>
      <li class="navelem"><a class="el" href="namespace_g_classes.html">GClasses</a>      </li>
      <li class="navelem"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html">GIncrementalLearnerQAgent</a>      </li>
      <li class="footer">Generated on Mon Dec 5 2011 14:19:03 for GClasses by&#160;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.3 </li>
    </ul>
  </div>

</body>
</html>
